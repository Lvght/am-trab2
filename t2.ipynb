{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  12 de Novembro de 2021\n",
    "</p>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img height=\"150\" src=\"https://www.ccs.ufscar.br/imagens/ufscar-preto.png\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img height=\"150\" src=\"https://site.dc.ufscar.br/static/media/LOGO-DC.295bfc37.svg\">\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "<h1 align=\"center\">Trabalho de Aprendizado de Máquina</h1>\n",
    "\n",
    "\n",
    "<h3 align=\"center\">Profº. Dr. Diego Furtado Silva</h3>\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  Bárbara Dib Oliveira (769717) <br>\n",
    "  Igor Teixeira Machado (769708) <br>\n",
    "  Lucas Machado Cid (769841) <br>\n",
    "  Vinicius Quaresma da Luz (769836)\n",
    "</p>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, importamos as bibliotecas necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking: list = [];\n",
    "\n",
    "def add_to_rank(entry: map):\n",
    "    ranking.append(entry)\n",
    "\n",
    "    # Ordena o ranking com base na chave 'score'\n",
    "    ranking.sort(key=lambda x: x['score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrega o dataset e divide-o em treinamento e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('datasets/student_data_por.csv')\n",
    "csvreader = csv.reader(file)\n",
    "header = next(csvreader)\n",
    "data = []\n",
    "\n",
    "for row in csvreader:\n",
    "  data.append(row)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Pega os dados crus e os divide em atributos e classes.\n",
    "for i in range(len(data)):\n",
    "    l: list = list(data[i])\n",
    "\n",
    "    # Os 3 últimos atributos são as notas.\n",
    "    X.append(l[:-3])\n",
    "\n",
    "    # Nota final.\n",
    "    score = l[-1]\n",
    "\n",
    "    numericScore = int(score)\n",
    "\n",
    "    # Obs.: As notas vão até 20.\n",
    "    if(numericScore < 10):\n",
    "      gradeRange = 0\n",
    "    else:\n",
    "      gradeRange = 1\n",
    "      \n",
    "    Y.append(gradeRange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usa um `OneHotEncoder` para transformar as variáveis categóricas em variáveis numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore');\n",
    "X = enc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz a padronização dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":warning: Ainda que a padronização não provoque alteração alguma no Grid Search do Decision Tree, ela faz com que a acurácia do kNN seja igual à acurácia do Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=False).fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide os dados em conjuntos de treinamento e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(X, Y, test_size = 0.2, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search para Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia obtida:  0.8923076923076924\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "param_grid = {'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': range(2,20,2),\n",
    "              'min_samples_leaf': range(2,10,2),\n",
    "              'min_impurity_decrease': np.linspace(0,0.5,10)}\n",
    "gs = GridSearchCV(classifier, param_grid=param_grid)\n",
    "\n",
    "gs.fit(x_tr, y_tr)\n",
    "y_pred = gs.predict(x_te)\n",
    "\n",
    "gs_dt_acc = accuracy_score(y_te, y_pred)\n",
    "add_to_rank({'classifier': 'Decision Tree', 'score': gs_dt_acc})\n",
    "\n",
    "print('Acurácia obtida: ', gs_dt_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faz um Grid Search para o kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia obtida:  0.8846153846153846\n",
      "Houve piora de  0.007692307692307776\n"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "classifier.fit(x_tr, y_tr)\n",
    "\n",
    "y_pred = classifier.predict(x_te)\n",
    "accuracy_score(y_te, y_pred)\n",
    "\n",
    "# Grid Search with classifier\n",
    "param_grid = {'weights': ['uniform', 'distance'],\n",
    "              'n_neighbors': range(1,15,2),\n",
    "              'metric': ['euclidean', 'manhattan']}\n",
    "gs = GridSearchCV(classifier, param_grid=param_grid)\n",
    "\n",
    "gs.fit(x_tr, y_tr)\n",
    "y_pred = gs.predict(x_te)\n",
    "\n",
    "gs_knn_acc = accuracy_score(y_te, y_pred)\n",
    "\n",
    "print('Acurácia obtida: ', gs_knn_acc)\n",
    "add_to_rank({'classifier': 'kNN', 'score': gs_knn_acc})\n",
    "\n",
    "if gs_knn_acc > gs_dt_acc:\n",
    "  print('Houve melhoria de ', gs_knn_acc - gs_dt_acc)\n",
    "else:\n",
    "    print('Houve piora de ', gs_dt_acc - gs_knn_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia obtida:  0.8153846153846154\n"
     ]
    }
   ],
   "source": [
    "# Importa o random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Calcula o random forest\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Usa o classifier para treinar\n",
    "classifier.fit(x_tr, y_tr)\n",
    "\n",
    "# Imprime a acurácia\n",
    "y_pred = classifier.predict(x_te)\n",
    "\n",
    "rf_acc = accuracy_score(y_te, y_pred)\n",
    "\n",
    "# imprime os resultados\n",
    "print('Acurácia obtida: ', rf_acc)\n",
    "add_to_rank({'classifier': 'Random Forest', 'score': rf_acc})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2076923076923077"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcula naive bayes com os dados padronizados\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_tr.toarray(), y_tr)\n",
    "\n",
    "accuracy_score(y_te, classifier.predict(x_te.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparação dos métodos usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'classifier': 'Random Forest', 'score': 0.8153846153846154}, {'classifier': 'Decision Tree', 'score': 0.7923076923076923}, {'classifier': 'kNN', 'score': 0.7846153846153846}]\n",
      "1 - Random Forest: 0.8153846153846154\n",
      "2 - Decision Tree: -0.023076923076923106\n",
      "3 - kNN: -0.007692307692307665\n"
     ]
    }
   ],
   "source": [
    "print(ranking)\n",
    "\n",
    "# Prints a ranking of classifiers showing difference to previous\n",
    "for i in range(len(ranking)):\n",
    "    if i == 0:\n",
    "        print(str(i+1) + ' - ' + ranking[i]['classifier'] + ': ' + str(ranking[i]['score']))\n",
    "    else:\n",
    "        print(str(i+1) + ' - ' + ranking[i]['classifier'] + ': ' + str(ranking[i]['score'] - ranking[i-1]['score']))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30971aefbb50f0decbc1e17b2c37f88e92c95c72013818a06d103efc0e1e37bd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
